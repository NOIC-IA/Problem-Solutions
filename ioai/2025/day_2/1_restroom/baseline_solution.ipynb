{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f1587d",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "This is the baseline solution you're given in the competition. Your objective is to improve it. This has been slightly adapted to run smoothly outside of Bohrium (2025 competition platform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e016e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clip\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e807e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)                  # Python built-in random\n",
    "np.random.seed(seed)               # NumPy\n",
    "torch.manual_seed(seed)            # PyTorch (CPU)\n",
    "torch.cuda.manual_seed(seed)       # PyTorch (single GPU)\n",
    "torch.cuda.manual_seed_all(seed)   # PyTorch (all GPUs)\n",
    "\n",
    "# Ensures deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_paths_by_number(path_list):\n",
    "    \"\"\"\n",
    "    Sort based on the numerical values of the filenames in the path,\n",
    "    assuming all filenames can be converted to integers.\n",
    "    \"\"\"\n",
    "    def get_file_number(path):\n",
    "        file_name = os.path.splitext(os.path.basename(path))[0]\n",
    "        return int(file_name)\n",
    "\n",
    "    path_list.sort(key=get_file_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce7d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_PATH = \"C:/Users/Home/Downloads/train_v1/train/\" # TODO: Upload data somewhere else\n",
    "model_path = \"C:/Users/Home/Documents/python]/Problem-Solutions/ViT-B-32.pt\" # TODO: Upload model somewhere else\n",
    "\n",
    "model, preprocess = clip.load(model_path, device=DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(img_paths):\n",
    "    \"\"\"\n",
    "    Compute L2‑normalized feature embeddings for a list of image file paths using the CLIP visual encoder.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    for path in tqdm(img_paths):\n",
    "        img = Image.open(path)\n",
    "        x = preprocess(img)\n",
    "        x = x.type(torch.float16).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            emb = model.visual.forward(x)\n",
    "\n",
    "        embeddings.append(emb)\n",
    "\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e66b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_images(BASE_DATA_DIR, result_path):\n",
    "    \"\"\"\n",
    "    For each query image in BASE_DATA_DIR/query, find its best matching image\n",
    "    in BASE_DATA_DIR/gallery by computing cosine similarity of CLIP embeddings,\n",
    "    then save 1‑based match indices to result_path as a .npy file.\n",
    "    \"\"\"\n",
    "    QUERY_DIR = BASE_DATA_DIR / \"query\"\n",
    "    NON_QUERY_DIR = BASE_DATA_DIR / \"gallery\"\n",
    "\n",
    "    query_image_paths = list(QUERY_DIR.glob(\"*.png\"))\n",
    "    non_query_image_paths = list(NON_QUERY_DIR.glob(\"*.png\"))\n",
    "\n",
    "    query_image_paths_str = [str(p) for p in query_image_paths]\n",
    "    non_query_image_paths_str = [str(p) for p in non_query_image_paths]\n",
    "\n",
    "    sort_paths_by_number(query_image_paths_str)\n",
    "    sort_paths_by_number(non_query_image_paths_str)\n",
    "\n",
    "    query_embeddings = infer(query_image_paths_str)\n",
    "    non_query_embeddings = infer(non_query_image_paths_str)\n",
    "    distances = torch.mm(query_embeddings, non_query_embeddings.t())\n",
    "    distances = (distances + 1.) / 2.\n",
    "\n",
    "    topk_dists, topk_idxs = torch.topk(distances, 11, dim=1)  # distances have shape (num_queries, num_non_queries)\n",
    "\n",
    "    topk_dists, topk_idxs = topk_dists.cpu(), topk_idxs.cpu()\n",
    "\n",
    "    matches_dists, matches_idxs = topk_dists[:, 1], topk_idxs[:, 1]\n",
    "    matches_dists = matches_dists.cpu().numpy()\n",
    "    matches_idxs = matches_idxs.cpu().numpy()\n",
    "\n",
    "    for i in range(len(matches_idxs)):\n",
    "        matches_idxs[i]+=1\n",
    "\n",
    "    np.save(result_path, matches_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc554f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "with tempfile.NamedTemporaryFile(suffix=\".npy\", delete=False) as tmp_a, \\\n",
    "    tempfile.NamedTemporaryFile(suffix=\".npy\", delete=False) as tmp_b:\n",
    "    submission_a_path = tmp_a.name\n",
    "    submission_b_path = tmp_b.name\n",
    "\n",
    "match_images(Path(DATA_PATH + \"test_a\"), submission_a_path)\n",
    "match_images(Path(DATA_PATH + \"test_b\"), submission_b_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730e83b7",
   "metadata": {},
   "source": [
    "## Scoring model\n",
    "This simulates how the leaderboard A and B would behave in the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f6b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import score\n",
    "\n",
    "score_a = score(\"submission_a.npy\", DATA_PATH + \"test_data.npy\")\n",
    "score_b = score(\"submission_b.npy\", DATA_PATH + \"validation_data.npy\")\n",
    "\n",
    "print(f\"Score A: {score_a:.4f}\\n Score B: {score_b:.4f}\")\n",
    "\n",
    "os.remove(submission_a_path)\n",
    "os.remove(submission_b_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
